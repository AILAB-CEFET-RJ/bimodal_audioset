{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use CPU only\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = '/home/rabreu/projeto_multimodal/'\n",
    "data_dir = project_dir+'data/'\n",
    "\n",
    "audioset_indices_csv = project_dir+'segments/subset_class_labels_indices.csv'\n",
    "\n",
    "## pegando dataset desbalanceado, que eu balanceei para 600 ocorrências para cada classe\n",
    "audioset_train_csv = project_dir+'segments/2000max_subset_unbalanced_train_segments.csv'\n",
    "audio_train_sub_dir = '2000unbalanced_train/audio'\n",
    "video_train_sub_dir = '2000unbalanced_train/video'\n",
    "\n",
    "audioset_eval_csv = project_dir+'segments/subset_eval_segments.csv'\n",
    "audio_eval_sub_dir = 'eval/audio'\n",
    "video_eval_sub_dir = 'eval/video'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregando dados avaliação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(532, 60, 420)\n",
      "(532, 32, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## audio\n",
    "save_dir = data_dir+audio_eval_sub_dir+\"/2000features/cnn/\"\n",
    "feature_file = os.path.join(save_dir+'_x.npy')\n",
    "labels_file = os.path.join(save_dir+'_y.npy')\n",
    "audio_eval_x = np.load(feature_file)\n",
    "## train_y and eval_y are only loaded once, since they are the same for audio and video\n",
    "eval_y = np.load(labels_file)\n",
    "print(audio_eval_x.shape)\n",
    "\n",
    "audio_eval_x = np.expand_dims(audio_eval_x, axis=-1)\n",
    "\n",
    "\n",
    "\n",
    "## video\n",
    "save_dir = data_dir+video_eval_sub_dir+\"/features/\"\n",
    "feature_file = os.path.join(save_dir+'_x.npy')\n",
    "video_eval_x = np.load(feature_file)\n",
    "print(video_eval_x.shape)\n",
    "\n",
    "## Mapeando valores de pixels para o espaço entre 0 e 1\n",
    "video_eval_x = video_eval_x.astype('float32')\n",
    "video_eval_x /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregando modelos e predizendo o conjunto de validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_model = load_model('modelos_salvos/2000audio_cnn.h5')\n",
    "video_model = load_model('modelos_salvos/2000video_cnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import top_3_accuracy\n",
    "multimodal_model = load_model('modelos_salvos/multimodal.h5', custom_objects={'top_3_accuracy': top_3_accuracy}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Audio Hamming Loss:', 0.1458109559613319)\n",
      "('Video Hamming Loss:', 0.17185821697099893)\n"
     ]
    }
   ],
   "source": [
    "audio_predictions = audio_model.predict([audio_eval_x])\n",
    "audio_predictions[audio_predictions>=0.5] = 1\n",
    "audio_predictions[audio_predictions<0.5] = 0\n",
    "\n",
    "\n",
    "video_predictions = video_model.predict([video_eval_x])\n",
    "video_predictions[video_predictions>=0.5] = 1\n",
    "video_predictions[video_predictions<0.5] = 0\n",
    "\n",
    "\n",
    "from sklearn.metrics import hamming_loss\n",
    "print(\"Audio Hamming Loss:\",hamming_loss(eval_y,audio_predictions))\n",
    "print(\"Video Hamming Loss:\",hamming_loss(eval_y,video_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Somando os valores de cada predição\n",
    "\n",
    "Será que as duas redes individuais combinadas se saem melhor?\n",
    "\n",
    "Vamos salvar os vetores de predição de cada uma das redes separadas(esses valores saíram dos arquivos jupyter de video e audio)\n",
    "\n",
    "Depois nós somamos as duas (ignorando valores acima de 1) e testamos as métricas para ver se está melhor que a multimodal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Hamming Loss:', 0.1683673469387755)\n",
      "(' F1 Score:', 0.57436493541268763)\n",
      "('Total of Exact match:', 160)\n",
      "('Accuracy of Exact match:', 0.3007518796992481)\n"
     ]
    }
   ],
   "source": [
    "mix_audio_video_pred = np.clip(np.add(audio_predictions,video_predictions),0,1)\n",
    "print(\"Hamming Loss:\",hamming_loss(eval_y,mix_audio_video_pred))\n",
    "from sklearn.metrics import  f1_score\n",
    "print(\" F1 Score:\",f1_score(eval_y, mix_audio_video_pred,average='macro'))\n",
    "\n",
    "predicted_diference = eval_y-mix_audio_video_pred\n",
    "correcly_predicted = (np.where(~(predicted_diference).any(axis=1))[0])\n",
    "print(\"Total of Exact match:\",correcly_predicted.shape[0])\n",
    "print(\"Accuracy of Exact match:\", float(correcly_predicted.shape[0])/eval_y.shape[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multilabel Confusion Matrix\n",
      "  TP,   FP,     TN,     FN, \n",
      "0 128\t112\t247\t45\n",
      "1 26\t18\t461\t27\n",
      "2 65\t55\t385\t27\n",
      "3 54\t130\t340\t8\n",
      "4 37\t28\t444\t23\n",
      "5 33\t46\t431\t22\n",
      "6 115\t39\t331\t47\n",
      "Σ 458\t428\t2639\t199\n",
      "\n",
      "F1 Score: 0.593649\n",
      "Recall: 0.697108\n",
      "Precision: 0.516930\n",
      "Hamming Loss: 0.168367\n"
     ]
    }
   ],
   "source": [
    "from utils import multilabel_confusion_matrix\n",
    "multilabel_confusion_matrix(eval_y,mix_audio_video_pred,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
